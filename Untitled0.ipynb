{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1OvAyQvylcOB4WuOIEmwcxB5oFM5KQP8W","authorship_tag":"ABX9TyNjIzdlrWEkL0IdECNgPmXX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MNFod6EoZ4zp","executionInfo":{"status":"ok","timestamp":1640612577959,"user_tz":-540,"elapsed":25355,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}},"outputId":"93f35319-9bdc-4f4c-b53f-abf4055caab3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mxnet\n","  Downloading mxnet-1.9.0-py3-none-manylinux2014_x86_64.whl (47.3 MB)\n","\u001b[K     |████████████████████████████████| 47.3 MB 1.5 MB/s \n","\u001b[?25hCollecting graphviz<0.9.0,>=0.8.1\n","  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.19.5)\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n","Installing collected packages: graphviz, mxnet\n","  Attempting uninstall: graphviz\n","    Found existing installation: graphviz 0.10.1\n","    Uninstalling graphviz-0.10.1:\n","      Successfully uninstalled graphviz-0.10.1\n","Successfully installed graphviz-0.8.4 mxnet-1.9.0\n","Collecting gluonnlp\n","  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n","\u001b[K     |████████████████████████████████| 344 kB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.19.5)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.24)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (21.3)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (3.0.6)\n","Building wheels for collected packages: gluonnlp\n","  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp37-cp37m-linux_x86_64.whl size=595717 sha256=95a3db389c375964b0f99c972c08f4f336511b5e5b994510bc15ce1b84c3f6ad\n","  Stored in directory: /root/.cache/pip/wheels/be/b4/06/7f3fdfaf707e6b5e98b79c041e023acffbe395d78a527eae00\n","Successfully built gluonnlp\n","Installing collected packages: gluonnlp\n","Successfully installed gluonnlp-0.10.0\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 5.1 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n","Collecting transformers==3.0.2\n","  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n","\u001b[K     |████████████████████████████████| 769 kB 5.1 MB/s \n","\u001b[?25hCollecting tokenizers==0.8.1.rc1\n","  Downloading tokenizers-0.8.1rc1-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 62.0 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (21.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2.23.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 47.7 MB/s \n","\u001b[?25hRequirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (0.1.96)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (3.4.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (4.62.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.2) (3.0.6)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.46 tokenizers-0.8.1rc1 transformers-3.0.2\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n"]}],"source":["!pip install mxnet\n","!pip install gluonnlp pandas tqdm\n","!pip install sentencepiece\n","!pip install transformers==3.0.2\n","!pip install torch"]},{"cell_type":"code","source":["!pip install git+https://github.com/SKTBrain/KoBERT.git@master"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LatiArTNaO8J","executionInfo":{"status":"ok","timestamp":1640612593512,"user_tz":-540,"elapsed":15557,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}},"outputId":"36e3aaee-814d-4546-b739-4f432702e02c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/SKTBrain/KoBERT.git@master\n","  Cloning https://github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-ynk5jgov\n","  Running command git clone -q https://github.com/SKTBrain/KoBERT.git /tmp/pip-req-build-ynk5jgov\n","Collecting boto3\n","  Downloading boto3-1.20.26-py3-none-any.whl (131 kB)\n","\u001b[K     |████████████████████████████████| 131 kB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: gluonnlp>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.1) (0.10.0)\n","Requirement already satisfied: mxnet>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.1) (1.9.0)\n","Collecting onnxruntime==0.3.0\n","  Downloading onnxruntime-0.3.0-cp37-cp37m-manylinux1_x86_64.whl (3.6 MB)\n","\u001b[K     |████████████████████████████████| 3.6 MB 42.3 MB/s \n","\u001b[?25hRequirement already satisfied: sentencepiece>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.1) (0.1.96)\n","Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.1) (1.10.0+cu111)\n","Collecting transformers>=4.8.1\n","  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n","\u001b[K     |████████████████████████████████| 3.4 MB 59.0 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp>=0.6.0->kobert==0.2.1) (1.19.5)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp>=0.6.0->kobert==0.2.1) (0.29.24)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp>=0.6.0->kobert==0.2.1) (21.3)\n","Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet>=1.4.0->kobert==0.2.1) (0.8.4)\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet>=1.4.0->kobert==0.2.1) (2.23.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.1) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.1) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.1) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.1) (3.0.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->kobert==0.2.1) (3.10.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.1) (3.4.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 45.5 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.1) (2019.12.20)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 57.4 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n","\u001b[K     |████████████████████████████████| 61 kB 683 kB/s \n","\u001b[?25hRequirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.1) (0.0.46)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.1) (4.8.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.1) (4.62.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp>=0.6.0->kobert==0.2.1) (3.0.6)\n","Collecting jmespath<1.0.0,>=0.7.1\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Collecting botocore<1.24.0,>=1.23.26\n","  Downloading botocore-1.23.26-py3-none-any.whl (8.5 MB)\n","\u001b[K     |████████████████████████████████| 8.5 MB 57.5 MB/s \n","\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n","  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 9.8 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.24.0,>=1.23.26->boto3->kobert==0.2.1) (2.8.2)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 79.3 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.26->boto3->kobert==0.2.1) (1.15.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=4.8.1->kobert==0.2.1) (3.6.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.8.1->kobert==0.2.1) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.8.1->kobert==0.2.1) (7.1.2)\n","Building wheels for collected packages: kobert\n","  Building wheel for kobert (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kobert: filename=kobert-0.2.1-py3-none-any.whl size=15267 sha256=e6ee53c17bd9ca86a68f2bc9c8d2b6481cc9c04ffc5b51607a528ef67d696612\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-sy6dah0t/wheels/9d/38/cd/bac1a57fdc97479873e50c017b628dc5b8e1084ec1c16694be\n","Successfully built kobert\n","Installing collected packages: urllib3, jmespath, pyyaml, botocore, tokenizers, s3transfer, huggingface-hub, transformers, onnxruntime, boto3, kobert\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.8.1rc1\n","    Uninstalling tokenizers-0.8.1rc1:\n","      Successfully uninstalled tokenizers-0.8.1rc1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 3.0.2\n","    Uninstalling transformers-3.0.2:\n","      Successfully uninstalled transformers-3.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed boto3-1.20.26 botocore-1.23.26 huggingface-hub-0.2.1 jmespath-0.10.0 kobert-0.2.1 onnxruntime-0.3.0 pyyaml-6.0 s3transfer-0.5.0 tokenizers-0.10.3 transformers-4.15.0 urllib3-1.25.11\n"]}]},{"cell_type":"code","source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import gluonnlp as nlp\n","import numpy as np\n","from tqdm import tqdm, tqdm_notebook\n","import pandas as pd\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"FOKFSIG-aWOE","executionInfo":{"status":"ok","timestamp":1640612603933,"user_tz":-540,"elapsed":10424,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["#kobert\n","from kobert.utils import get_tokenizer\n","from kobert.pytorch_kobert import get_pytorch_kobert_model\n","\n","#transformers\n","from transformers import AdamW\n","from transformers.optimization import get_cosine_schedule_with_warmup\n","\n","device = torch.device(\"cuda:0\")"],"metadata":{"id":"ROv0vlEzaYq0","executionInfo":{"status":"ok","timestamp":1640612606515,"user_tz":-540,"elapsed":2593,"user":{"displayName":"김보석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjn9RdJkJIesGDUmE8JTZrRsciTZIupvfj7xz1LvA=s64","userId":"08969752424908754753"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#BERT 모델, Vocabulary 불러오기\n","bertmodel, vocab = get_pytorch_kobert_model()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K8smPLhdabDK","outputId":"ecf85b44-8aaf-4e12-a71d-fadc0ace3fa3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/.cache/kobert_v1.zip[██████████████████████████████████████████████████]\n"]}]},{"cell_type":"code","source":["cd drive/Othercomputers/내 노트북/googleDrive/BMO-AI"],"metadata":{"id":"fQqLo89ka2ZD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["__연속적 데이터는 중립 값이 너무 많아 데이터로써 활용하기가 힘듦__"],"metadata":{"id":"yLAS0_lOwfIf"}},{"cell_type":"code","source":["data1 = pd.read_excel('한국어_단발성_대화_데이터셋.xlsx')\n","data2 = pd.read_excel('한국어_연속적_대화_데이터셋.xlsx')"],"metadata":{"id":"Aqn8f0OnaePF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(data1)"],"metadata":{"id":"i6SbN-mSbOwB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(data2)"],"metadata":{"id":"kQq1PXBObWc1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data1.sample(n=10)"],"metadata":{"id":"OcL32uKtbXAF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data2.sample(n=10)"],"metadata":{"id":"wP-AaHmtbbY-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data1 = data1.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', '공포', 5468], axis=1)\n","data1"],"metadata":{"id":"2xPrQVEddWOD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data1['Emotion'].value_counts()"],"metadata":{"id":"WnnK8jcvo0oe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data1.loc[(data1['Emotion'] == '공포'), 'Emotion'] = 0\n","data1.loc[(data1['Emotion'] == '놀람'), 'Emotion'] = 1\n","data1.loc[(data1['Emotion'] == '분노'), 'Emotion'] = 2\n","data1.loc[(data1['Emotion'] == '슬픔'), 'Emotion'] = 3\n","data1.loc[(data1['Emotion'] == '중립'), 'Emotion'] = 4\n","data1.loc[(data1['Emotion'] == '행복'), 'Emotion'] = 5\n","data1.loc[(data1['Emotion'] == '혐오'), 'Emotion'] = 6"],"metadata":{"id":"B4mZ-vyxie_q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_list = []\n","for q, label in zip(data1['Sentence'], data1['Emotion']):\n","    data = []\n","    data.append(q)\n","    data.append(str(label))\n","    data_list.append(data)"],"metadata":{"id":"8v0S4pZvh3Bn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_list"],"metadata":{"id":"5C-2VZ8riF4_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(data_list)"],"metadata":{"id":"zXdV1AwRw3aK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_train, dataset_test = train_test_split(data_list, test_size=0.1, random_state=0)"],"metadata":{"id":"EOcIyfvuiak6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(dataset_train))\n","print(len(dataset_test))"],"metadata":{"id":"jLzxOkF5jO5J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["type(dataset_train)"],"metadata":{"id":"AEEL-njFj82b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# BERT 모델에 들어가기 위한 dataset을 만들어주는 클래스\n","class BERTDataset(Dataset):\n","    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n","                 pad, pair):\n","        transform = nlp.data.BERTSentenceTransform(\n","            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n","\n","        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n","        self.labels = [np.int32(i[label_idx]) for i in dataset]\n","\n","    def __getitem__(self, i):\n","        return (self.sentences[i] + (self.labels[i], ))\n","\n","    def __len__(self):\n","        return (len(self.labels))"],"metadata":{"id":"8RsoBQ0yjRIr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Setting parameters\n","max_len = 64\n","batch_size = 64\n","warmup_ratio = 0.1\n","num_epochs = 5\n","max_grad_norm = 1\n","log_interval = 200\n","learning_rate =  5e-5"],"metadata":{"id":"0BQ_LqO0jar_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#토큰화\n","tokenizer = get_tokenizer()\n","tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n","\n","data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n","data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)"],"metadata":{"id":"M1eW6drPjdvd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train[0]"],"metadata":{"id":"yxxKnwozb3b8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n","test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"],"metadata":{"id":"UpBC4XdTxBFw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class BERTClassifier(nn.Module):\n","    def __init__(self,\n","                 bert,\n","                 hidden_size = 768,\n","                 num_classes=7,   ##클래스 수 조정##\n","                 dr_rate=None,\n","                 params=None):\n","        super(BERTClassifier, self).__init__()\n","        self.bert = bert\n","        self.dr_rate = dr_rate\n","                 \n","        self.classifier = nn.Linear(hidden_size , num_classes)\n","        if dr_rate:\n","            self.dropout = nn.Dropout(p=dr_rate)\n","    \n","    def gen_attention_mask(self, token_ids, valid_length):\n","        attention_mask = torch.zeros_like(token_ids)\n","        for i, v in enumerate(valid_length):\n","            attention_mask[i][:v] = 1\n","        return attention_mask.float()\n","\n","    def forward(self, token_ids, valid_length, segment_ids):\n","        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n","        \n","        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n","        if self.dr_rate:\n","            out = self.dropout(pooler)\n","        return self.classifier(out)"],"metadata":{"id":"roz9tgKCxEIM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)"],"metadata":{"id":"wRfq4r-HxHqd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Prepare optimizer and schedule (linear warmup and decay)\n","no_decay = ['bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","]"],"metadata":{"id":"8c5PjfOtxJ0E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n","loss_fn = nn.CrossEntropyLoss()"],"metadata":{"id":"cQ330aBMxl4H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["t_total = len(train_dataloader) * num_epochs\n","warmup_step = int(t_total * warmup_ratio)"],"metadata":{"id":"5pqDpKRWxnVC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"],"metadata":{"id":"SFHkeunWxpSq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calc_accuracy(X,Y):\n","    max_vals, max_indices = torch.max(X, 1)\n","    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n","    return train_acc"],"metadata":{"id":"VdrtzxZgxqy_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataloader"],"metadata":{"id":"IidFdpilxtI7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"iQ4WjQoUxvUh"},"execution_count":null,"outputs":[]}]}